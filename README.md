This article explores the potential of transformer-based models for computer vision tasks, specifically image classification and object detection, without the reliance on traditional neural networks. By leveraging the self-attention mechanism of transformers, we propose alternative architectures that eschew convolutional and fully connected layers. Our approach demonstrates that transformers can effectively perform image recognition and object detection tasks, offering new insights into the design of vision models. The experimental results show competitive performance with traditional CNN-based methods, highlighting the feasibility of transformer-only architectures for computer vision.

The repository contains an image classification and an object detection project. Both the projects use transformers for its vision task.

Read more about it in the article --> https://galvanized-thing-028.notion.site/Vision-without-Neural-Networks-97fcf55240de4abc9dc1279dbbe32bb0?pvs=4

Vision Transformer's result
![vit](https://github.com/user-attachments/assets/35c926cc-88ce-474c-bf3e-ce850382b998)

Detection Transformer result
![detr](https://github.com/user-attachments/assets/7b325818-c728-41c0-a589-1635361e8f78)
